# Conclusion
-   This project demonstrates how interpretable machine learning methods like LIME and SHAP can be effectively applied to credit scoring models to improve both performance and transparency. Among the models tested, logistic regression proved to be more reliable than the decision tree, especially in identifying high-risk applicants. Key features such as application status, credit history, loan duration, and installment rate were found to have the greatest influence on predictions. The interpretability results also show that practical financial factors like longer repayment periods, lack of collateral, and additional debt obligations play a consistent role in pushing predictions toward high risk. Overall, this approach supports more informed and responsible decision-making in credit risk assessment by combining strong model performance with clear explanations.

## Limitations

-   One limitation of this project is the reliance on a relatively small and dated dataset, which may not fully reflect the complexity and diversity of modern credit environments. The features used are static and do not account for changes in borrower behavior or financial status over time, which could impact prediction accuracy in real-world applications. Additionally, while LIME and SHAP offer local and global interpretability, their effectiveness may be reduced when features are highly correlated or when model behavior is strongly nonlinear. Further work is needed to explore more advanced models and validate findings using larger and more representative datasets.